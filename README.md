# UT3-TFU Andis II

## Pasos para correrlo:
1. npm install
2. docker compose up --build
3. npx serve

## Configuraci√≥n:
- Las variables de entorno est√°n en el archivo `.env`
- Los usuarios est√°n definidos en `userService.js`
- La aplicaci√≥n corre en puerto 3000 (contenedor) y se expone directamente en puerto 8080
- Configurado para usar exactamente 8 workers (escalabilidad horizontal)

## Permisos:
- **Alice (cliente)**: Puede ver productos, acceder a recursos protegidos, y crear √≥rdenes.
- **Bob (admin)**: Puede crear/modificar productos, gestionar clientes, ver √≥rdenes, pero NO puede crear √≥rdenes (solo los clientes pueden comprar).

## Pasos para el postman:

### GetHealth
GET http://localhost:8080/health

---
### LoginWithAlice
POST http://localhost:8080/login

    {
      "username": "alice",

      "password": "alicepass"
    }

---
### LoginWithBob
POST http://localhost:8080/login

    {
      "username": "bob",

      "password": "bobpass"
    }

---
### ProtectedWithTokenAlice
GET http://localhost:8080/protected

- Key: Authorization
- Value: Bearer {Token id de Alice}

---
### ProtectedWithTokenBob
GET http://localhost:8080/protected

- Key: Authorization
- Value: Bearer {Token id de Bob}

---
### AdminOnly
GET http://localhost:8080/admin-only

- Key: Authorization
- Value: Bearer {Token id de Bob}

---
### ListOfProductsAlice
GET http://localhost:8080/products

- Key: Authorization
- Value: Bearer {Token id de Alice}

---
### CreateProduct
POST http://localhost:8080/products

- Key: Authorization
- Value: Bearer {Token id de Bob}


      {
        "name": "Producto 3",
        
        "price": 300
      }

---
### ModifyProduct
PUT http://localhost:8080/products/p1

- Key: Authorization
- Value: Bearer {Token id de Bob}

      {
        "name": "Producto 3",

        "price": 300
      }

---
### GetClients (Admin only)
GET http://localhost:8080/clients

- Key: Authorization
- Value: Bearer {Token id de Bob}

---
### CreateClient (Admin only)
POST http://localhost:8080/clients

- Key: Authorization
- Value: Bearer {Token id de Bob}

      {

        "name": "Cliente Nuevo"

      }

---
### GetOrders (Admin only)
GET http://localhost:8080/orders

- Key: Authorization
- Value: Bearer {Token id de Bob}

---
### CreateOrder (Clientes only - NO admin)
POST http://localhost:8080/orders

- Key: Authorization
- Value: Bearer {Token id de Alice}

      {

        "clientId": 1,

        "productIds": [1, 2]

      }

**Response** incluye: total calculado, informaci√≥n del cliente y productos

**Nota**: Los administradores (Bob) NO pueden crear √≥rdenes, solo los clientes (Alice)

## Justificaci√≥n de la partici√≥n:

### Modelo de Componentes UML

![alt text](/docs/image.png)

Mermaid Code:


    flowchart LR
        API[API REST]
        Productos[M√≥dulo Productos]
        Clientes[M√≥dulo Clientes]
        Ordenes[M√≥dulo √ìrdenes]
        Interfaces[(Interfaces)]

        API --> Productos
        API --> Clientes
        API --> Ordenes

        Productos ..> Interfaces
        Clientes ..> Interfaces
        Ordenes ..> Interfaces

---
### Descripci√≥n de componentes
- API REST: Recibe las peticiones y las env√≠a al m√≥dulo correspondiente. Utiliza clustering con 8 workers para escalabilidad horizontal.
- M√≥dulo Productos: Maneja la informaci√≥n de los productos.
- M√≥dulo Clientes: Maneja la informaci√≥n de los clientes.
- M√≥dulo √ìrdenes: Crea y muestra las √≥rdenes usando datos de productos y clientes.
- Interfaces: Permiten que los m√≥dulos se comuniquen entre s√≠.

---
### Justificaci√≥n de partici√≥n de primer nivel
La partici√≥n se realiz√≥ por dominio funcional (productos, clientes, √≥rdenes) para facilitar escalabilidad, mantenimiento y despliegue independiente.

---
### Proceso para encontrar los componentes
Se analizaron los requerimientos del dominio e-commerce y se identificaron los m√≥dulos funcionales principales. Cada m√≥dulo expone interfaces para interacci√≥n y desacoplamiento.

---
### Contenedores vs M√°quinas Virtuales
Se eligieron contenedores (Docker) por su ligereza, velocidad de despliegue y facilidad de escalado horizontal. Si se usaran m√°quinas virtuales, el despliegue ser√≠a m√°s pesado y menos eficiente para escalar instancias r√°pidamente.

---
### ACID vs BASE
La demo utiliza servicios sin estado y simula operaciones BASE, priorizando disponibilidad y escalabilidad. Si se usara ACID, se sacrificar√≠a escalabilidad y velocidad de respuesta por consistencia fuerte y transacciones.

---
### Teorema CAP (Brewer) - An√°lisis de nuestro sistema

En nuestro sistema hemos elegido **AP (Availability + Partition Tolerance)** del teorema CAP:

#### ‚úÖ **A - Availability (Disponibilidad):**
- **8 workers con clustering**: Si un worker falla, otros siguen funcionando
- **Reinicio autom√°tico**: Workers que fallan se reinician autom√°ticamente
- **Servicios sin estado**: No hay dependencia de estado local, cualquier worker puede responder
- **Health checks**: Endpoint `/health` para monitoreo de disponibilidad

#### ‚úÖ **P - Partition Tolerance (Tolerancia a particiones):**
- **Servicios desacoplados**: M√≥dulos independientes que se comunican por interfaces
- **Sin base de datos centralizada**: No hay single point of failure
- **Contenedores**: Cada instancia es independiente y puede ejecutarse en diferentes nodos

#### ‚ùå **C - Consistency (Consistencia):**
**Sacrificamos consistencia fuerte por las siguientes razones:**

- **Datos hardcodeados**: Productos, clientes y √≥rdenes no persisten entre requests
- **Sin transacciones**: Las operaciones no son ACID
- **Eventual consistency**: Los datos pueden ser inconsistentes temporalmente
- **Servicios sin estado**: Cada request es independiente, no hay sincronizaci√≥n de estado

#### üéØ **Justificaci√≥n de la elecci√≥n AP:**

**¬øPor qu√© elegimos Availability sobre Consistency?**
1. **E-commerce de demo**: Priorizamos que el sistema est√© siempre funcionando
2. **Escalabilidad horizontal**: M√°s importante poder agregar workers que tener consistencia perfecta
3. **Tolerancia a fallos**: Mejor que algunos workers fallen a que todo el sistema sea inconsistente
4. **Experiencia de usuario**: Los usuarios prefieren un sistema disponible aunque tenga datos ligeramente desactualizados

**¬øQu√© impacto tendr√≠a elegir CP (Consistency + Partition tolerance)?**
- ‚ùå Tendr√≠amos que implementar base de datos con transacciones ACID
- ‚ùå Menor disponibilidad: si la DB falla, todo el sistema falla
- ‚ùå Menor escalabilidad: necesitar√≠amos sincronizaci√≥n entre workers
- ‚ùå Mayor complejidad: manejo de locks, deadlocks, rollbacks

**¬øQu√© impacto tendr√≠a elegir CA (Consistency + Availability)?**
- ‚ùå No tolerar√≠amos particiones de red
- ‚ùå Sistema monol√≠tico: todos los componentes en un solo nodo
- ‚ùå Sin escalabilidad horizontal
- ‚ùå Single point of failure
